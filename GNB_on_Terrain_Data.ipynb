{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GNB on Terrain Data.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vZqx323xUcEg"
      },
      "outputs": [],
      "source": [
        "def classify(features_train, labels_train):   \n",
        "    ### import the sklearn module for GaussianNB\n",
        "    ### create classifier\n",
        "    ### fit the classifier on the training features and labels\n",
        "    ### return the fit classifier\n",
        "    \n",
        "    \n",
        "    ### your code goes here!\n",
        "    from sklearn.naive_bayes import GaussianNB\n",
        "    clf = GaussianNB()\n",
        "    return clf.fit(features_train, labels_train)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "def makeTerrainData(n_points=1000):\n",
        "###############################################################################\n",
        "### make the toy dataset\n",
        "    random.seed(42)\n",
        "    grade = [random.random() for ii in range(0,n_points)]\n",
        "    bumpy = [random.random() for ii in range(0,n_points)]\n",
        "    error = [random.random() for ii in range(0,n_points)]\n",
        "    y = [round(grade[ii]*bumpy[ii]+0.3+0.1*error[ii]) for ii in range(0,n_points)]\n",
        "    for ii in range(0, len(y)):\n",
        "        if grade[ii]>0.8 or bumpy[ii]>0.8:\n",
        "            y[ii] = 1.0\n",
        "\n",
        "### split into train/test sets\n",
        "    X = [[gg, ss] for gg, ss in zip(grade, bumpy)]\n",
        "    split = int(0.75*n_points)\n",
        "    X_train = X[0:split]\n",
        "    X_test  = X[split:]\n",
        "    y_train = y[0:split]\n",
        "    y_test  = y[split:]\n",
        "\n",
        "    grade_sig = [X_train[ii][0] for ii in range(0, len(X_train)) if y_train[ii]==0]\n",
        "    bumpy_sig = [X_train[ii][1] for ii in range(0, len(X_train)) if y_train[ii]==0]\n",
        "    grade_bkg = [X_train[ii][0] for ii in range(0, len(X_train)) if y_train[ii]==1]\n",
        "    bumpy_bkg = [X_train[ii][1] for ii in range(0, len(X_train)) if y_train[ii]==1]\n",
        "\n",
        "#    training_data = {\"fast\":{\"grade\":grade_sig, \"bumpiness\":bumpy_sig}\n",
        "#            , \"slow\":{\"grade\":grade_bkg, \"bumpiness\":bumpy_bkg}}\n",
        "\n",
        "    grade_sig = [X_test[ii][0] for ii in range(0, len(X_test)) if y_test[ii]==0]\n",
        "    bumpy_sig = [X_test[ii][1] for ii in range(0, len(X_test)) if y_test[ii]==0]\n",
        "    grade_bkg = [X_test[ii][0] for ii in range(0, len(X_test)) if y_test[ii]==1]\n",
        "    bumpy_bkg = [X_test[ii][1] for ii in range(0, len(X_test)) if y_test[ii]==1]\n",
        "\n",
        "    test_data = {\"fast\":{\"grade\":grade_sig, \"bumpiness\":bumpy_sig}\n",
        "            , \"slow\":{\"grade\":grade_bkg, \"bumpiness\":bumpy_bkg}}\n",
        "\n",
        "    return X_train, y_train, X_test, y_test\n",
        "#    return training_data, test_data"
      ],
      "metadata": {
        "id": "y7JNxE0cUo4Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import matplotlib \n",
        "matplotlib.use('agg')\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import pylab as pl\n",
        "import numpy as np\n",
        "\n",
        "#import numpy as np\n",
        "#import matplotlib.pyplot as plt\n",
        "#plt.ioff()\n",
        "\n",
        "def prettyPicture(clf, X_test, y_test):\n",
        "    x_min = 0.0; x_max = 1.0\n",
        "    y_min = 0.0; y_max = 1.0\n",
        "\n",
        "    # Plot the decision boundary. For that, we will assign a color to each\n",
        "    # point in the mesh [x_min, m_max]x[y_min, y_max].\n",
        "    h = .01  # step size in the mesh\n",
        "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
        "    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
        "\n",
        "    # Put the result into a color plot\n",
        "    Z = Z.reshape(xx.shape)\n",
        "    plt.xlim(xx.min(), xx.max())\n",
        "    plt.ylim(yy.min(), yy.max())\n",
        "\n",
        "    plt.pcolormesh(xx, yy, Z, cmap=pl.cm.seismic)\n",
        "\n",
        "    # Plot also the test points\n",
        "    grade_sig = [X_test[ii][0] for ii in range(0, len(X_test)) if y_test[ii]==0]\n",
        "    bumpy_sig = [X_test[ii][1] for ii in range(0, len(X_test)) if y_test[ii]==0]\n",
        "    grade_bkg = [X_test[ii][0] for ii in range(0, len(X_test)) if y_test[ii]==1]\n",
        "    bumpy_bkg = [X_test[ii][1] for ii in range(0, len(X_test)) if y_test[ii]==1]\n",
        "\n",
        "    plt.scatter(grade_sig, bumpy_sig, color = \"b\", label=\"fast\")\n",
        "    plt.scatter(grade_bkg, bumpy_bkg, color = \"r\", label=\"slow\")\n",
        "    plt.legend()\n",
        "    plt.xlabel(\"bumpiness\")\n",
        "    plt.ylabel(\"grade\")"
      ],
      "metadata": {
        "id": "z4dwU0E2Uo6v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pylab as pl\n",
        "\n",
        "features_train, labels_train, features_test, labels_test = makeTerrainData()\n",
        "\n",
        "### the training data (features_train, labels_train) have both \"fast\" and \"slow\" points mixed\n",
        "### in together--separate them so we can give them different colors in the scatterplot,\n",
        "### and visually identify them\n",
        "grade_fast = [features_train[ii][0] for ii in range(0, len(features_train)) if labels_train[ii]==0]\n",
        "bumpy_fast = [features_train[ii][1] for ii in range(0, len(features_train)) if labels_train[ii]==0]\n",
        "grade_slow = [features_train[ii][0] for ii in range(0, len(features_train)) if labels_train[ii]==1]\n",
        "bumpy_slow = [features_train[ii][1] for ii in range(0, len(features_train)) if labels_train[ii]==1]\n",
        "\n",
        "clf = classify(features_train, labels_train)\n",
        "\n",
        "### draw the decision boundary with the text points overlaid\n",
        "prettyPicture(clf, features_test, labels_test)"
      ],
      "metadata": {
        "id": "dQxRr4YdUo8z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def NBAccuracy(features_train, labels_train, features_test, labels_test):\n",
        "    \"\"\" compute the accuracy of your Naive Bayes classifier \"\"\"\n",
        "    ### import the sklearn module for GaussianNB\n",
        "    from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "    ### create classifier\n",
        "    clf = GaussianNB()\n",
        "\n",
        "    ### fit the classifier on the training features and labels\n",
        "    clf.fit(features_train,labels_train)\n",
        "\n",
        "    ### use the trained classifier to predict labels for the test features\n",
        "    pred = clf.predict(features_test)\n",
        "\n",
        "    ### calculate and return the accuracy on the test data\n",
        "    accuracy = clf.score(features_test, labels_test)\n",
        "    return accuracy"
      ],
      "metadata": {
        "id": "TK4YNzqdUo_O"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}